# Outlier detection Lecture 11
## 2022-12-05

### What is an outlier?
* An outlier is an observation that deviates significantly from other members of the sample in which it occurs (Grubbs 1969)
* Has been studied a lot since the 70's
* An outlier is a distinct observation that is seemed to be generated by a different mechanism
* To decide whether a sample is an outlier we look at the majority of samples to establish a standard. 
### Outlier detection 
The problem of finding patterns in data that do not conform to expected normal behaviour

Outliers have different names depending on the field in which it is being studied at. 

Example of outlier detection: 

* An anamolous MRI image -> precence of malignant tumors

#### Challenges in outlier detection problem
It is hard to identify what the boundary between normal and abnormal is. There are many domains where these overlap. 

The concept of what is normal can even be changed, if my interest is reading scientific books one day, but then some other day decide to prefer world news. My new preference can initially be seen as abnormal but will with time become the new norm

##### Nature of input data
Input data is generally a collection of data instances which are described using a set of attribute. 

There are problems where you have one feature called univariate whilst many features for a sample is called multivariate.

Data can come in many forms:

* Binary
* Categorical 
* Continous

The nature of attributes determines the applicability of outlier detection techniques 

E.g. different statistical models are required for continous and categorical data

Input data can be categorized based on relationship present among data instances

Most anomaly detections dealing with point data assume no relationship among the data instances

Data instances can be related to each other:

* Sequence data is an example e.g. timeseries data
* Spatial data, each instance is related to its neighboring instances. Ecological data and climate data are good examples. (The latter is incidentally also sequenced data called spatio-temporal data)
* Graph data -> vetices: data instance 
    
    edge: relationship between instances
##### Availability of the labeled data
In most real-world scenarios we don't have data that is representative of both normal and abnormal data which creates issues in when training models. The problem lies in the nature of this type of data, the majority of data will ofcourse be normal, thus a small selection can only be anamoulous, this creates skewed sets. Outliers are by nature imbalanced

#### Constraints and requirements of the application domain problem
Your solution will almost always be domain specific as it is tailored to your data

### Outlier vs. Noise
They are related but distinct

* Noise can be defined as a phenomenon in data that is not of interest. We should remove noise at the beginning of data cleaning to so we can study the relevant behaviours and outliers

##### Type of noise
* Attribute noise (missing values introduced by measurement tools for example)
* Class noise (mislabeled instances by humans)
* A combination of both

Can be solved through colaboration with domain expert, or visualising the problem to get a better grasp

* Outliers are considered interesting and or unknown patterns that we want to investigate further to gain potentially new insights

### Data distrubition
The majority of data can (when labeled is not available) be assumed to be normal data

A small fraction will be noise & anomalies.

### Type of outliers

#### Point outliers: 
Definition: An individual data point distinct from the entire dataset (global) 

Point anomalies can occur in any set


  * E.g, credit car fraud detection based on spikes of money spent
  * A high spike outside of the normal range, without any reasonable explanation can be seen as a point outlier


#### Contextual outliers 

Definition: A data point that deviates significantly with respect to a specific context or condition. 

Contextual anomalies depend on the availabilty of context attributes in the data. 
  
* Context is related to the structure of data and each instance is defined using two important variables
  * e.g spatial data (longitiude, latitude) represents the context. A strong deviation from its neighbours is considered to be an outlier (A drop in temperature of 20 degrees in june for example)
  * sequence data (time)
  
* Behavioral attributes: define the non-contextual characteristics of an instance
  
#### Collective outliers: 
A collection (sequence) of related data points that deviates significantly from the entire data set. 
  
* Each point it self is normal, but in succession is what makes them an outlier 
* Walk dog-> feed dog -> walk dog -> walk dog-> walk dog 

### Creating models with outliers
Methods:

* oversample from the minority class by including duplicates
* undersample: take less samples from the majority class
* Define what is normal and only model normality
  * Is known as semi-supervised learning
  * More widely applicable than supervised techniques -> there is no need for labels of the anomaly class
  
### Outputs of outlier detection
* Scoring by assigning a value to each instance
* Domain experts can use a domain specific threshold to select the most relevant anomalies and convert it to categorical data (alternatively implement a confidence interval)

## Sharooz's experiences
When working with a company make sure that the data exists. Especially if they say it is labelled, the data has to be useful. 

A minimum spanning tree is the subtree with the minimum cost of traversing. It is very popular in telecommunication. 

Working with real-world data is not easy :(

# Lecture 12 How to write a Machine-Learning thesis 

## What is a thesis? 

* A systematic study of a chosen hypothesis
  * A hypothesis is an explanation for some phenomenon
  * A hypothesis is supposed to be falsifiable through experimentation. 
  * The hypothesis should allign with the research question you're studying. If you don't know what your research question or hypothesis is you can't apply a systematic methodology. 
* The goal is to substantiate or refute the hypothesis  
* A thesis is a contribution to a single or interdisciplinary field of research's pool of knowledge
  * Master thesis does not have to break new ground, just show that you have a good grasp of the field in question.
 
## Defining and testing a hypothesis
A scientific hypothesis must be falsifiable. This is the dividing line between science and pseudoscience. The hypothesis should be measurable ,observable and exact. A hypothesis which leaves a lot up for intepretation is not a proper hypothesis 

Relevant aspects to consider: 

* Testability: the degree to which it canbe substantiated or refuted
* Complexity: the amount of assumptions involved (more assumptions makes it harder to assess the hypothesis)
* scope: the generaliszbility of the statement (to other phenomena)
  * Can your method be extended to other domains or is it tailormade for the specific question in mind
* Usefulness: the degree to which it can predict future observations
  * Is our method tied to our data set or is it useful for more than that?

## Thinking about causality
There are variables that are dependent and independent which could be good to understand the nature of it. The structural causal model is a method of showing relations through acyclic, directed graphs. In certain fields, you have to show that there is a relationship between the features in question, this does not apply to computer science as we have the ability to choose our variables. 

Multiple variables feeding into an output requires keeping all but one static to truly understand their effect initially. You can then compare each piece by piece and finally together. 

Noise might exist through no fault of our own, whether it is due to the operating system or some other factor out of our hand. Repeat the experiment multiple times to get a good reading 

## Thesis criteria
Look through requirements for theses at bth before doing your thesis. Study the evaluation criteria to know what is expected. 

# Writing a machine learning thesis
## Finding topics
Focus ofn the type of research

* Applied research: use available machine learning for solving a specific problem
* Basic research: extend machine learning to create something new

If you decide to do applied research, more times than not you will work with a company. Before choosing which company, make sure they have the data relevant to the task which they want to solve. Not all companies know if their data is sufficent, it is a judgement you have to do. 

Focus on research method or the type of contribution
* theoretical (algorithms, ideas, proofs)
* Empirical (experiments, casestudies, interviews)
* Constructive (implementations, prototypes, etc)

More often than not a thesis will contribute in some amount to each of these fields. If your thesis proposes a new algorithm, testing it might be a natural part of the process

Read, listen, and watch what others have done and want to do in the future

check suggested topics from your supervisor if they are related to the field. 

check competitions (kaggle.com, etc.)
* These are good cause they come as a package, but you still need to apply a systematic approach 

## Developing the topic 
* Once a particular topic (an algorith, a machine learning problem or task, and applied problem. a real world challenge, etc) has been chosen you need to make it a thesis topic
* Difficult to come up with something completely novel and useful
* It is easier to vary some aspects of something that is known
  * Extend algorithm to new purpose 
  * make new comparision or evaluation of existing algorithms 
  * define new challenge or use new date

## Find and rank sources
### Different types of sources
Wikipedia is a good introduction to the topic. A good source when you want to look into the domain

Text books as more trusted, comprehensive overview of a topic or subject

  * Not always updated or in line with your research question

Literature reviews/surveys as introduction and overview of a newly delvelopting topic or area.
  
  * A good way to know what is going on in the field right now quickly

Peer-reviewed research articles are the best sources in terms of quality. But you have to judge the quality on your own to make sure the paper is good

### methods to find sources 
Search in databases 

### A method to see if a paper was published in a trusted journal
Ranks journals based on their acceptance rate of papers and the relevant keywords you've put in. 
portal.core.edu.au/conf-ranks/
### Reviewing to etract information
* reviewing to extract information 
  * Determine if the article is withing scope based on title and abstract
  * Read introduction and conclusions- what has been done, why ,what are the results
  * if needed, read additional parts of the paper
* Grade the following aspects
  * Contribution (originality, significance, relvance)
  * Understandability, replicability (technical quality, presentation quality)
    * If you can replicate the results through the paper then it is good
* Do not get discouraged by difficult math-- try to understand the written text, read alternative explanations, or ask someone 

### Planning 
Plan early, review continously and revise accordingly 

* a good plan has aclear aim, well defined, acitivities with concrete deliverables and a reasonable time schedule

Keep detailed but brief notes on everything deemed important

* you might remember it now but not in 2 months when it is actually relevant

Keep deadlines and use human resources wisely and politely

* Contact your supervisor in advance and brief on what you need help with in advance to allow him to prepare

Allow a majority of total time for writing and revising

* this is what you present to everyone else, you need to constantly develop your report throughout the project. Do parts of the paper as they become available or "doable"
  
Allow yourself to be creative (don't be afriad of doing something in your way instead of the "common" way)

* There are of course standards for a reason, but sometimes they do not translate perfectly for your research question. 

Get inspired by master theses from recognized universities

* Study the way they write their thesis and how they conduct their research

Be consistent when organising, analysing and reporting work

* Establish regular meetings with your supervisor, even if there is nothing to be presented or reported it is good to have these timeslots to brief on current progress. 

### What to do when you get stuck
There are usually many strategies to try

1. Carefully review your work
2. Explain the problem to lay people in a manner appropriate to get new insights
3. look forsources related to your problems 
4. Identify problems possible causes and reasonable solutions
    * Explore causes and solutions as tree search with reasonable heuristics and maintain a realistic depth control
5. Document the problem, tried solutions, and outcomes
6. Talk to your peers
7. Talk to your supervisor (and other teachers)
   *  Be professional clear, and thoughtful. Do not spend a week trying to brute force it, look for alternatives
8. Go back to step 1'
### What not to do
* Start working without an aim a plan or atime budget,
* Spend a majority of the time hacking
  * This is only a part of the process in producing your thesis, your paper is the end product
* Contact the supervisor before trying hard to solve the problem
* Ask the supervisor about course rules and dealdlines
* Use tools without understanding how they work and why
* Make general and strong claims without evidence or justification
* use the supervisor as proof reading service
  * make sure it is understandable and not full of gramatical mistakes, 
  * your supervisor should proof read your methodology not the grammar
* follow online courses and read wikipedia articles instead of reading organizing, analyzing and synthezising peer-reviewed articles.
  * Your information should be from peer-reviewed articles

### Evalutation
Choose an appropairate metric
  * This depends on the balance of your dataset
   
idealy perform  10 x 10-fold cross-validation

* This gives you a 100 performance measures, which gives a better picture than just one. However 10 x 10-fold cross-validation requires time and resources consider your resources. 
* When running tests, allow your system to go to idle between tests to make sure less noise presents itself. 

When using predfined test set -- do not use it when designing the algorithm

Visualize results

* A really important part of your paper is presenting your results in a coherent manner.
* The visualization should be intepretable and create insight

Use statistic hypothesis tests to confirm or reject your hypothesis
